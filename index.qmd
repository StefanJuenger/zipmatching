---
title: "(Assessment of) Geospatial Linking of Incongruent Units"
author: 
  - "Anne Stroppe"
  - "Stefan Jünger"
image: img/logo_areamatch.jpg
---


```{r, echo = F}

knitr::opts_chunk$set(
  echo = TRUE, 
  fig.align = "center", 
  message = FALSE,
  warning = FALSE
)

```

# At a glance

<!-- to be added  -->


# Introduction

Data integration of social indicators from surveys with geospatial context variables has rapidly progressed. 
Applications in the social sciences are manifold, covering issues such as conflict and migration, political participation, environmental attitudes, and inequality. 
Geospatial approaches allow researchers to introduce new perspectives in explaining societal processes and emphasize the local aspects of globally relevant questions.

As an example, this tool application addresses the discourse on the rural-urban divide, which has received considerable attention in recent years. 
Rural areas can serve as breeding grounds for political discontent because citizens’ perceptions of their living environment may foster a sense of neglect, resource deprivation, and lack of societal respect. 
Consequently, citizens may become more susceptible to far-right narratives, which could explain the rise of populist and far-right sentiments in rural areas. 
Therefore, one central research question is: Is living in a less densely populated area, such as a rural place, associated with far-right party preferences?
To answer this question, it is necessary to link survey data with information about the respondents’ living environment.

The linking process is crucial to answer this research question but is prone to certain pitfalls, such as incongruent geospatial units, e.g. overlapping geospatial units that do not share a common border.
In many (online) surveys, respondents can indicate where they live by, for example, entering the ZIP code of their home address. 
This information allows for the linking of contextual information about the respondents’ living environment, like population density, to the survey data. 
However, contextual information is often not available at the ZIP code level.
Instead, it refers to administrative units, such as municipalities. 
These two different spatial units are often not congruent, increasing uncertainty in the linking process.

```{r, echo = F}

# Load necessary libraries
library(sf)
library(ggplot2)
library(dplyr)


# Function to create a realistic polygon for Municipality 1
create_municipality_polygon <- function() {
  coords <- matrix(c(
    0, 0,     # Bottom-left
    3, 1.5,   # Bottom-right
    4, 2.5,   # Middle-right
    3, 3,     # Top-right
    0, 3,     # Top-left
    -1, 1.5,  # Middle-left
    0, 0      # Closing the polygon
  ), ncol = 2, byrow = TRUE)
  
  st_polygon(list(coords)) |>
    st_sfc(crs = 4326) |>
    st_sf()
}

# Create Municipality 1
municipality1 <- create_municipality_polygon()
municipality1$id <- "Municipality 1"

# Function to create a realistic polygon for Postal Code Area 1
create_zip_code_polygon1 <- function() {
  coords <- matrix(c(
    1, 0,     # Bottom-left
    3, 0,     # Bottom-right
    3, 2,     # Top-right
    1, 2,     # Top-left
    1, 0      # Closing the polygon
  ), ncol = 2, byrow = TRUE)
  
  st_polygon(list(coords)) |>
    st_sfc(crs = 4326) |>
    st_sf()
}

# Create Postal Code Area 1
zip_code1 <- create_zip_code_polygon1()
zip_code1$id <- "ZIP Code Area 1"


# Combine the shapes into a single data frame for plotting
zip_codes <- zip_code1


# Plot the selected municipality and postal code areas with overlap highlighted
ggplot() +
  geom_sf(data = municipality1, aes(fill = id), alpha = 0.5, color = "black") +
  geom_sf(data = zip_codes, aes(fill = id), alpha = 0.5, color = "black") +
  scale_fill_brewer(palette = "Set3") +
  labs(title = "Overlapping But Incongruent Boundaries",
       fill = "Layers") +
  theme_minimal() +
  theme(legend.position = "right")


```

This tool addresses this challenge by highlighting linking techniques that can be used to successfully link the datasets and assessing the uncertainty of the linking process.

# Data Prerequisites and Description

To replicate this tool, researchers need the following:

- Survey data that includes an identifier for the target areal units where respondents reside and for which the attribute needs to be linked or estimated
- The geometries of the target areal units 
- The geometries of the source unit that include the attributes information they are interested in

For this tool application, we rely on three data sources: (synthetic) survey data including self-reported ZIP codes, the geographies of German ZIP code areas, and the geographies of German municipalities, including attributes of interest, in this case population density.

We base our analysis example on survey data from the German Longitudinal Election Study (GLES). 
The GLES Tracking consists of short cross-sectional online surveys (CAWI) conducted three times a year.
Each cross-sectional sample includes approximately 1,000 respondents.
For this analysis, we create a synthetic data set based on the [GLES Tracking November 2023, T56](https://search.gesis.org/research_data/ZA7714). 
Respondents were asked to indicate their approval of the German radical right party AfD on a scale from 1 ("I don't think highly of this party at all") to 11 ("I think very highly of this party") (variable t14h). 
At the end of the questionnaire, they were also asked to enter the 5-digit ZIP code of their primary residence (variable t71).

::: {.callout-important}
Due to data protection regulations, ZIP codes cannot be published in the Scientific Use Files of the survey data but only accessed through the [Secure Data Center at GESIS](https://www.gesis.org/en/services/processing-and-analyzing-data/analysis-of-sensitive-data/secure-data-center-sdc). For this tool application, we provide simulated data that reproduces the real correlation of the GLES data without allowing conclusions to be drawn about the place of residence or the interviewee.
:::

The two additional data sources provide the necessary geographies of ZIP code areas and municipalities and their corresponding attributes. 
We rely on the Open Data portal ArcGIS Hub to access the geometries of the [German ZIP code areas](https://hub.arcgis.com/maps/esri-de-content::postleitzahlengebiete-in-deutschland) and [municipalities](https://hub.arcgis.com/maps/60eb682c95f44ba7b10fee66d871859d).
Data can be downloaded directly as a shapefile or GeoPackage file. 
We work with a geospatial data type called vector data, which is organized similarly to any other data table: each row represents a geometric object (e.g., a ZIP code area or a municipality), and each column holds an attribute (e.g., population density).
For detailed information on handling geospatial data and using the package `sf`, you can refer to our course [“Introduction to Geospatial Techniques for Social Scientists in R”](https://stefanjuenger.github.io/gesis-workshop-geospatial-techniques-R-2024/).

# Tool Functions To Assess the Spatial Linking Process

This tool application provides replicable code to guide the user through the linking process and assess their linking strategy. The tutorial highlights the following steps:

- Centroid linkage: This technique involves linking data based on the central point (centroid) of a geographic area. For example, the centroid of a ZIP code area is linked to the municipality in which the centroid is located.

- Areal matching: This method matches entire areas to one another, such as linking ZIP code areas to municipalities based on the largest overlapping area.

- Areal interpolation: This technique redistributes data from one set of geographic units to another. The basic approach, area weighted spatial interpolation, takes into account the size of the areal overlap and assigns the value of the overlapping area in proportion to the overlap. 

- Overall Assessment of Linking Techniques: Evaluates the differences, effectiveness, and accuracy of the different linking techniques to determine the best method for integrating the survey and geospatial data at hand.

- Influence of Linking Technique on Research Question: Analyzes how the choice of linking technique affects the outcomes and interpretations of the research question, ensuring that the conclusions drawn are robust and reliable.

# Getting started

## Packages

There are several packages out there that allow geospatial data handling in R.
Since we are working mainly with vector data, we heavily rely on the package [sf](https://doi.org/10.32614/CRAN.package.sf).
The packages `dplyr`, `ggplot2`, and `tibble` are used for data manipulation and visualization.


```{r }

# Load necessary packages ----

library(dplyr)       # For data manipulation
library(ggplot2)     # For data visualization
library(sf)          # For handling spatial (geometric) data
library(tibble)      # For creating and managing tibbles (data frames)

```

## Geospatial Data

In Germany, the 5-character zip code areas often do not align with municipal boundaries, leading to both overlap and incongruence. This mismatch can be more pronounced in rural areas, where larger zip code regions may encompass multiple small municipalities. In contrast, urban areas tend to have several distinct zip codes that fall within a single municipality. For example, the capital Berlin, as a German 'city-state', is one municipality with 190 zip codes.

When selecting and loading the geospatial data, we always check for three sources of errors:
- Consistent (projected) coordinate reference systems. In our case, both shapefiles are projected in WGS 84 (EPSG: 3857).
- Timeliness of administrative boundaries and territorial reforms. For example, we use the 2022 municipality boundaries and the 2023 zip code areas.
- Existence, column names, and format of identifiers and variables of interest. For instance, we require the zip code and municipality code to be in character format in our data frame.

```{r}

# Load zip code data ----

zip_codes <-
  # Load spatial data from GeoPackage file
  sf::st_read("./data-raw/PLZ_Gebiete_7155512659375659703.gpkg") |>
  # Select only relevant columns: zip code and population
  dplyr::select(zip_code = plz, inhabitants_zip_code = einwohner)

# Load municipality data ----

municipalities <-
  # Load spatial data from GeoPackage file
  sf::st_read("./data-raw/Gemeindegrenzen_2022__mit_Einwohnerzahl_4398740898366155627.gpkg") |>
  # Select AGS (municipality code) and population columns
  dplyr::select(ags = AGS, inhabitants_municipality = EWZ)

```

We also advice to always plot the data for a visual inspection of the prjection and completeness of the geospatial information.

```{r, echo = F}

library(patchwork)

# Create the municipalities plot
g_mun <- ggplot(data = municipalities) +
  ggplot2::geom_sf(fill = "lightgrey", color = "black", size = 0.05) +  
  ggplot2::ggtitle("Municipalities") +
  ggplot2::theme_minimal() 

# Create the zip codes plot
g_zip <- ggplot() +
  ggplot2::geom_sf(data = zip_codes, fill = "lightgrey", color = "black", size = 0.05) + 
# ggplot2::geom_sf(data = zip_codes_reduced, fill = "red", color = "black") +
  ggplot2::ggtitle("Zip Codes") +
  ggplot2::theme_minimal() 

# Combine the two plots using patchwork
g_mun + g_zip



```


## Survey Data

Due to data protection regulations, we cannot use real-world survey data, but we base our tool application on simulated data that were created on  the basis of the [GLES Tracking November 2023, T56](https://search.gesis.org/research_data/ZA7714). 
To prepare the simulated data, we clean the original survey data to retain only valid zip codes and then link the data with geospatial data using centroid and areal matching techniques, followed by area-weighted interpolation for population and area estimates. 
Finally, we calculate correlations between the variable of interest, "afd_rating" and from the geospatial data derived population densities.
In a next step, we generate random ZIP codes, introducing some invalid entries to mimic the real-world data.
We repeat the linking process and then simulate the dependent variable based on the original correlations to derive the simulated data.
To replicate the creation of the simulated survey data, we provide the R-Script [here](./test/create_simulated_survey.R).

```{r}

survey <- readRDS("./data-raw/simulated_survey_data.rds")

```


#  Inspecting data

Before linking survey data, it is crucial to inspect the zip codes provided by respondents, especially when  participants entered their zip codes independently.
The self-reported nature of data entry can lead to several issues, like refusal to respond or typographical errors, which can result in invalid or missing zip codes. 
The provided code categorizes the self-reported zip codes into three statuses: "Non Response", "Invalid ZIP Code" (For instance, zip codes that are not five characters long or that do not exist in the predefined list of valid zip codes), and "Valid". 
By utilizing this categorization, researchers can identify and address potential data quality issues before data integration.
<!--- footnote: could also try to resolve issues with zip codes -->

```{r}

# Create a new column 'status' to categorize the zip codes
survey <- survey |>
  dplyr::mutate(
    # Use case_when to classify each zip_code into different statuses
    status = dplyr::case_when(
      # Condition 1: If zip_code is NA, classify as "1 Non Response"
      is.na(zip_code) ~ "1 Non Response",
      # Condition 2: If zip_code does not have exactly 5 characters, 
      # classify as "2 Invalid ZIP Code"
      nchar(zip_code) != 5 ~ "2 Invalid ZIP Code",
      # Condition 3: If zip_code is not found in the list of valid zip codes, 
      # classify as "2 Invalid ZIP Code"
      !zip_code %in% zip_codes$zip_code ~ "2 Invalid ZIP Code",
      # Condition 4: If zip_code is found in the list of valid zip codes, 
      # classify as "3 Valid"
      zip_code %in% zip_codes$zip_code ~ "3 Valid"
    )
  )

# Create a summary table to count the occurrences of each status
summary_table <- survey |>
  dplyr::group_by(status) |>  # Group the data by the 'status' column
  dplyr::summarise(
    # Count the number of occurrences for each status
    count = dplyr::n(),  
    # Calculate the frequency 
    freq = (dplyr::n() / nrow(survey)) * 100  
  ) |>
  # Convert the result into a tibble for easier viewing and manipulation
  tibble::as_tibble()  

print(summary_table)

```

In this case, `r summary_table$freq[summary_table$status == "1 Non Response"]`% of respondents did not answer the zip code question, and `r summary_table$freq[summary_table$status == "2 Invalid ZIP Code"]`% provided an invalid zip code. What we do not check here is whether respondents entered their correct zip code. Depending on the data at hand, it might be possible to verify whether other self-reported data, such as the federal state, or data from other sources align with this information.

For the ongoing linking process, we exclude all observations that did not enter a zip code or entered an invalid one, working instead with a subsample of all valid zip codes in the survey. Since we will use more spatial techniques in the following analysis, we rely on this reduced spatial data frame.

```{r}

# Create a reduced dataset based on the valid zip codes from the survey data
zip_codes_valid <-
  survey |>
  # Filter the survey data to include only rows with a valid zip code status
  dplyr::filter(status == "3 Valid") |>
  # Perform a left join with the zip_codes dataset on the 'zip_code' column
  dplyr::left_join(zip_codes, ., by = "zip_code") |>
  # Convert the resulting data frame to a simple features (sf) 
  sf::st_as_sf()

```

::: {.callout-important} 
If you want to create a complete matching list between all zip codes and all municipalities in Germany, you can also use the complete zip code data set. However, it might take a while to create this data set and run the spatial joins. <!-- The script and data are provided under additional material -->
:::


# Matching methods

## Data praperation  {#sec-simpoints}

We're sampling 1,000 points within each valid zip code area to later assess the accuracy of our linking techniques. 
By simulating 1,000 hypothetical living locations for respondents who reported living in a specific zip code area, we can evaluate whether our method accurately aligns each sampled point with the correct municipality.
This approach allows us to identify any discrepancies or inaccuracies in the linking process and compare the three linking methods.

```{r}

# Sample points within zip code areas ----
# Randomly sample points within each zip code area. Note: This can take a long
# time due to the number of points sampled.
points_in_zip_codes <-
  zip_codes_valid |>
  # Sample 1000 points per area
  sf::st_sample(size = c(1000, 1000), progress = TRUE, exact = FALSE) |>
  # Convert sampled points to an sf object
  sf::st_as_sf() |>
  # Spatially join sampled points with zip code data
  sf::st_join(zip_codes) |>
  # Arrange points by zip code for easier viewing
  dplyr::arrange(zip_code) |>
  # Assign unique IDs to each sampled point
  dplyr::mutate(id = 1:dplyr::n()) |>
  # Select only the ID and zip code columns
  dplyr::select(id, zip_code)


# Join sampled points with municipality inhabitants data ----
# Spatially join the sampled points data with municipality data to match each
# point with actual inhabitants data from municipalities
points_with_real_inhabitants_municipality <-
  points_in_zip_codes |>
  # Join points with municipality data
  sf::st_join(municipalities) |>
  # Rename population column for clarity
  dplyr::rename(real_inhabitants_municipality = inhabitants_municipality)



```

## Centroid matching

This method uses the centroid (center point) of each zip code area to find the corresponding municipality.
It assumes that the center point accurately represents the zip code's location in terms of municipality boundaries.

```{r, echo = F}

library(patchwork)

# Function to create a realistic polygon for Municipality 1
create_municipality_polygon <- function() {
  coords <- matrix(c(
    0, 0,     # Bottom-left
    3, 0.5,   # Bottom-right
    4, 2.5,   # Middle-right
    3, 3,     # Top-right
    0, 3,     # Top-left
    -1, 1.5,  # Middle-left
    0, 0      # Closing the polygon
  ), ncol = 2, byrow = TRUE)
  
  st_polygon(list(coords)) |>
    st_sfc(crs = 4326) |>
    st_sf()
}

# Create Municipality 1
municipality1 <- create_municipality_polygon()
municipality1$id <- "Municipality"

# Function to create a realistic polygon for Postal Code Area 1
create_zip_code_polygon1 <- function() {
  coords <- matrix(c(
    1, 0,     # Bottom-left
    3, 0,     # Bottom-right
    3, 2,     # Top-right
    1, 2,     # Top-left
    1, 0      # Closing the polygon
  ), ncol = 2, byrow = TRUE)
  
  st_polygon(list(coords)) |>
    st_sfc(crs = 4326) |>
    st_sf()
}

# Create Postal Code Area 1
zip_code1 <- create_zip_code_polygon1()
zip_code1$id <- "ZIP Code"


# Combine the shapes into a single data frame for plotting
fake_zip_codes <- zip_code1

fake_zip_codes_centroid <- sf::st_centroid(fake_zip_codes)


# Add centroids to zip code data


# Function to create a realistic polygon for Municipality 1
create_municipality_polygon <- function() {
  coords <- matrix(c(
    0, 0.15,     # Bottom-left
    1.5, 0.15,   # Bottom-right
    2, 1.5,
    2.2, 1,
    2.4, 0.15,   # Middle-right
    3.8, 0.4,
    3.5, 3,     # Top-right
    0, 3,     # Top-left
    1.5, 2.5,
    -1, 1.5,  # Middle-left
    0, 0.15      # Closing the polygon
  ), ncol = 2, byrow = TRUE)
  
  st_polygon(list(coords)) |>
    st_sfc(crs = 4326) |>
    st_sf()
}

# Create Municipality 1
municipality2 <- create_municipality_polygon()
municipality2$id <- "Municipality"
zip_code1$id <- "ZIP Code"

library(viridis)
# Generate colors from the inferno palette
inferno_colors <- viridis::inferno(4)

# Create a named vector for fill colors
color_mapping1 <- c(
  "Municipality" = inferno_colors[2],       # Color for Municipality
  "Fake Zip Codes" = inferno_colors[3],      # Color for Fake Zip Codes
  "Centroid" = "red"                         # Color for Centroid
)

# Set desired legend order
desired_order1 <- c("Municipality", "Fake Zip Codes", "Centroid")

# Plot for municipality1
map1 <- ggplot() +
  geom_sf(data = municipality1, aes(fill = factor("Municipality", levels = desired_order1)), alpha = 0.75, color = "black") +
  geom_sf(data = fake_zip_codes, aes(fill = factor("Fake Zip Codes", levels = desired_order1)), alpha = 0.5, color = "black") +
  geom_sf(data = fake_zip_codes_centroid, aes(fill = factor("Centroid", levels = desired_order1)), shape = 20, color = "red", size = 3) +
  scale_fill_manual(values = color_mapping1, name = "Layers") +
  labs(title = "High Accuracy") +
  theme_minimal() +
  theme(legend.position = "right")

# Plot for municipality2
map2 <- ggplot() +
  geom_sf(data = municipality2, aes(fill = factor("Municipality", levels = desired_order1)), alpha = 0.75, color = "black") +
  geom_sf(data = fake_zip_codes, aes(fill = factor("Fake Zip Codes", levels = desired_order1)), alpha = 0.5, color = "black") +
  geom_sf(data = fake_zip_codes_centroid, aes(fill = factor("Centroid", levels = desired_order1)), shape = 20, color = "red", size = 3) +
  scale_fill_manual(values = color_mapping1, name = "Layers") +
  labs(title = "Low Accuracy") +
  theme_minimal() +
  theme(legend.position = "right")

# Combine the two plots using patchwork
(map1 | map2) + plot_layout(guides = "collect") +
  plot_annotation(title = "Accuracy of Centroid Linking")

```

One benefit of this approach is its simplicity and efficiency, allowing for a quick linking process. 
However, a drawback is that it may overlook important local variations, as the centroid may not accurately reflect the distribution of residents or land use within the zip code area, nor does it account for the actual overlap or shape of the units.
To do the linking process, we need to calculate centroids for each zip code and use the `sf::st_join` function to identify in which municipality each centroid is located.

```{r}

# Centroid linking ----
centroid_matched <-
  zip_codes_valid |>
  # Calculate the centroid for each zip code area
  sf::st_point_on_surface() |>
  # Spatially join centroids with municipality data
  sf::st_join(municipalities) |>
  # Select relevant columns
  dplyr::select(zip_code, inhabitants_zip_code, inhabitants_municipality) |>
  # Remove any duplicate rows
  dplyr::distinct() |>
  # Arrange by zip code for easy viewing
  dplyr::arrange(zip_code)

```

## Areal matching

This method assigns each zip code area to the municipality in which the  majority of its area lies.

```{r, echo = FALSE}


# Function to create a realistic polygon for Municipality 1
create_municipality_polygon <- function() {
  coords <- matrix(c(
    0, 0,     # Bottom-left
    1, 0,
    3.05, 0.52,   # Bottom-right
    3.4, 1.5,   # Middle-right
    3, 2,     # Top-right
    0.5, 2,     # Top-left
    0.8, 1.5,  # Middle-left
    0, 0     # Closing the polygon
  ), ncol = 2, byrow = TRUE)
  
  st_polygon(list(coords)) |>
    st_sfc(crs = 4326) |>
    st_sf()
}

# Create Municipality 1
municipality1 <- create_municipality_polygon()
municipality1$id <- "Municipality 1"


create_municipality_polygon <- function() {
  coords <- matrix(c(
    0, 0,     # Bottom-left
    1,0,
    3.05, 0.52,   # Bottom-right
    3.4, 1.5,   # Middle-right
    3.4,-0.5,
    0,0
  ), ncol = 2, byrow = TRUE)
  
  st_polygon(list(coords)) |>
    st_sfc(crs = 4326) |>
    st_sf()
}

municipality2 <- create_municipality_polygon()
municipality2$id <- "Municipality 2"

# Function to create a realistic polygon for Postal Code Area 1
create_zip_code_polygon1 <- function() {
  coords <- matrix(c(
    1, -0.5,     # Bottom-left
    3, -0.5,    # Bottom-right
    3, 1.5,     # Top-right
    1, 1.5,     # Top-left
    1, -0.5      # Closing the polygon
  ), ncol = 2, byrow = TRUE)
  
  st_polygon(list(coords)) |>
    st_sfc(crs = 4326) |>
    st_sf()
}

# Create Postal Code Area 1
zip_code1 <- create_zip_code_polygon1()
zip_code1$id <- "ZIP Code"


# Overlapping Area
# Function to create a realistic polygon for Postal Code Area 1
create_overlap_polygon <- function() {
  coords <- matrix(c(
    1, 0,     # Bottom-left
    3, 0.5,    # Bottom-right
    3, 1.5,     # Top-right
    1, 1.5,     # Top-left
    1, 0       # Closing the polygon
  ), ncol = 2, byrow = TRUE)
  
  st_polygon(list(coords)) |>
    st_sfc(crs = 4326) |>
    st_sf()
}

overlap <- create_overlap_polygon()
overlap$id <- "Largest Areal Overlap"




# Plot the selected municipality and postal code areas with overlap highlighted


# Create a named vector for fill colors
color_mapping2 <- c(
  "Municipality 1" = inferno_colors[1],  # Color for Municipality 1
  "Municipality 2" = inferno_colors[2],  # Color for Municipality 2
  "Zip Code" = inferno_colors[3],        # Color for Zip Code
  "Overlap" = inferno_colors[4]          # Color for Overlap
)

# Set desired legend order
desired_order2 <- c("Municipality 1", "Municipality 2", "Zip Code", "Overlap")

# Create a plot
ggplot() +
  geom_sf(data = municipality1, aes(fill = factor("Municipality 1", levels = desired_order2)), alpha = 0.4, color = "black") +  # Color for Municipality 1
  geom_sf(data = municipality2, aes(fill = factor("Municipality 2", levels = desired_order2)), alpha = 0.4, color = "black") +  # Color for Municipality 2
  geom_sf(data = zip_code1, aes(fill = factor("Zip Code", levels = desired_order2)), alpha = 0.5, color = "blue") +      # Color for Zip Code
  geom_sf(data = overlap, aes(fill = factor("Overlap", levels = desired_order2)), alpha = 0.8, color = "red", size = 1.5) +  # Color for Overlap
  scale_fill_manual(values = color_mapping2, 
                    name = "Layers") +  # Use the named vector for specific colors
  labs(title = "Areal Matching: Largest Overlap") +
  theme_minimal() +
  theme(legend.position = "right")

```

The `sf::st_join` function identifies which municipality overlaps with each zip code area. 
The `largest = TRUE` argument indicates that if a zip code overlaps with multiple municipalities, it will only keep the municipality with the largest overlapping area.

In comparison to centroid matching, areal matching takes the full geographic shape of the zip code area into account, providing a more precise association with municipalities based on actual boundaries. 
One drawback of areal matching is that it can be computationally more intensive, especially when working with a large number of areal units. 
Another complication is that if multiple municipalities overlap with a zip code, additional decisions must be made about which municipality to assign.
In this application, we take a straightforward approach and assign the municipality with the largest overlap.
However, if the overlap shares are equal, this could resemble a coin toss.

```{r}


# Areal matching method ----

areal_matched <-
  zip_codes_valid |>
  # Spatial join using the largest overlap municipality for each zip code area
  sf::st_join(municipalities, left = TRUE, largest = TRUE) |>
  # Select relevant columns
  dplyr::select(zip_code, inhabitants_zip_code, inhabitants_municipality) |>
  # Remove duplicates to ensure each zip code matches one municipality
  dplyr::distinct() |>
  # Sort by zip code
  dplyr::arrange(zip_code)

```

## Areal interpolation

This method uses areal interpolation to distribute municipality inhabitants data proportionally across overlapping ZIP code areas.


```{r, echo = FALSE}

library(sf)
library(ggplot2)
library(dplyr)

# Function to create a realistic polygon for Municipality 1
create_municipality_polygon1 <- function() {
  coords <- matrix(c(
    0, 0,     # Bottom-left
    1, 0,
    3, 0.5,   # Bottom-right
    3.4, 1.5, # Middle-right
    3, 2.5,   # Top-right
    0.5, 2.5, # Top-left
    0.8, 1.5, # Middle-left
    0, 0      # Closing the polygon
  ), ncol = 2, byrow = TRUE)
  
  st_polygon(list(coords)) |>
    st_sfc(crs = 4326) |>
    st_sf()
}

# Create Municipality 1
municipality1 <- create_municipality_polygon1()
municipality1$id <- "Municipality 1"

# Function to create a realistic polygon for Municipality 2
create_municipality_polygon2 <- function() {
  coords <- matrix(c(
    0, 0,     # Bottom-left
    1, 0,
    3, 0.5,   # Bottom-right
    3.4, 1.5, # Middle-right
    3.4, -0.8,  # Bottom-right extension
    0, 0      # Closing the polygon
  ), ncol = 2, byrow = TRUE)
  
  st_polygon(list(coords)) |>
    st_sfc(crs = 4326) |>
    st_sf()
}

# Create Municipality 2
municipality2 <- create_municipality_polygon2()
municipality2$id <- "Municipality 2"

# Function to create a realistic polygon for Postal Code Area
create_zip_code_polygon <- function() {
  coords <- matrix(c(
    1, -0.5,  # Bottom-left
    3, -0.5,  # Bottom-right
    3, 1.5,   # Top-right
    1, 1.5,   # Top-left
    1, -0.5   # Closing the polygon
  ), ncol = 2, byrow = TRUE)
  
  st_polygon(list(coords)) |>
    st_sfc(crs = 4326) |>
    st_sf()
}

# Create Postal Code Area
zip_code <- create_zip_code_polygon()
zip_code$id <- "ZIP Code"


# Create geometries for each municipality's share in the interpolation area
interpolated_municipality1 <- st_intersection(zip_code, municipality1) # Share from Municipality 1
interpolated_municipality1$id <- "Share from Municipality 1"

interpolated_municipality2 <- st_intersection(zip_code, municipality2) # Share from Municipality 2
interpolated_municipality2$id <- "Share from Municipality 2"

# Combine the shares into a single data frame
shares_combined <- rbind(interpolated_municipality1, interpolated_municipality2)


# Generate colors from the inferno palette
inferno_colors <- viridis::inferno(5)  # Generate 5 colors to use for distinct layers

# Create a named vector for fill colors
color_mapping3 <- c(
  "Municipality 1" = inferno_colors[1],     # Color for Municipality 1
  "Municipality 2" = inferno_colors[2],     # Color for Municipality 2
  "Zip Code" = inferno_colors[3],           # Color for Zip Code
  "Shares Municipality 1" = inferno_colors[4],  # Color for Shares of Municipality 1
  "Shares Municipality 2" = inferno_colors[5]   # Color for Shares of Municipality 2
)

# Set desired legend order
desired_order3 <- c("Municipality 1", "Municipality 2", "Zip Code", "Shares Municipality 1", "Shares Municipality 2")


# Create the plot
ggplot() +
  geom_sf(data = municipality1, aes(fill = factor("Municipality 1", levels = desired_order3)), alpha = 0.5, color = "black") +  # Color for Municipality 1
  geom_sf(data = municipality2, aes(fill = factor("Municipality 2", levels = desired_order3)), alpha = 0.5, color = "black") +  # Color for Municipality 2
  geom_sf(data = zip_code, aes(fill = factor("Zip Code", levels = desired_order3)), alpha = 0.5, color = "blue") +      # Color for Zip Code
  geom_sf(data = interpolated_municipality1, aes(fill = factor("Shares Municipality 1", levels = desired_order3)), alpha = 0.7, color = "red") +  # Shares for Municipality 1
  geom_sf(data = interpolated_municipality2, aes(fill = factor("Shares Municipality 2", levels = desired_order3)), alpha = 0.7, color = "orange") +  # Shares for Municipality 2
  scale_fill_manual(values = color_mapping3, 
                    name = "Layers") +  # Use the named vector for specific colors
  labs(title = "Area-weighted Spatial Interpolation") +
  theme_minimal() +
  theme(legend.position = "right")

```

It estimates the inhabitants for each ZIP code based on the proportion of its area that overlaps with each municipality by:

1. Overlap Calculation: For each zip code area, the function determines how much of its area overlaps with each municipality and, as such, calculates the intersection of each unit of both areal unit layers.

2. Proportional Distribution: Once the overlaps are identified, it calculates the proportion of each municipality's area that overlaps with the zip code area. 

3. Population Estimation: The estimated population for each zip code area is then computed by multiplying the municipality's population by the overlap proportion. For example, if a municipality has 10,000 inhabitants and 40% of its area overlaps with a particular zip code, then 4,000 inhabitants would be allocated to that zip code area. If multiple municipalities overlap with a zip code area, it sums the estimated populations from each municipality to get the total population for that zip code.

As such, a key advantage of areal interpolation is its flexibility, as it can effectively manage irregular boundaries and varying sizes of geographic units. 
Nonetheless, it operates under the assumption that populations are uniformly distributed within areas, which may not reflect reality and can lead to inaccuracies if the input data is flawed or unrepresentative.
Similar to areal matching, the process can be computationally demanding, especially when dealing with multiple overlapping areas and variable populations, as well as a large number of indicators that need to be interpolated.

```{r}

# Areal interpolation matching method ----

areal_interpolation_matched <-
  sf::st_interpolate_aw(
    # Use municipality inhabitants data for interpolation
    municipalities["inhabitants_municipality"],
    # Target zip code areas for the interpolation
    zip_codes_valid,
    # Set to FALSE as population data is not "extensive" (not purely additive)
    extensive = FALSE
  ) |>
  # Combine interpolated results with original zip code data
  dplyr::bind_cols(
    zip_codes_valid |>
      # Drop geometry to avoid duplication issues in final output
      sf::st_drop_geometry() |>
      # Select only zip code and its inhabitants count
      dplyr::select(zip_code, inhabitants_zip_code)
  ) |>
  # Choose relevant columns for output
  dplyr::select(zip_code, inhabitants_zip_code, inhabitants_municipality) |>
  # Ensure unique rows
  dplyr::distinct() |>
  # Sort by zip code
  dplyr::arrange(zip_code)

```

For advanced users, we would also like to point out the package [`areal`](https://github.com/chris-prener/areal) that builds upon the `sf`package we use here and expands the functions for area weighted interpolations [@Prener].

# Assessing the matching methods

<!-- exchange for population density? -->

## Data preparation

In @sec-simpoints, we sampled nearly 1,000,000 points to simulate 1,000 hypothetical living locations within each ZIP code area. 
This allows us to assess the accuracy and consistency of the linking process and compare the three matching methods. 
The step is crucial because, for each simulated point, we know the exact municipality match, which provides the correct value for the number of inhabitants in the respondents' municipality.

It is important to note that we focus on the differences in the number of inhabitants per municipality to evaluate the matching process because that is our main variable of interest.
Specifically, if a ZIP code area overlaps with spatial clusters of municipalities that have a similar number of inhabitants - areas with high positive spatial autocorrelation - the differences will naturally be smaller, even if the matching methods yield different results.
Therefore, the evaluation of the linking process — and ultimately the selection of the most appropriate method — should consider the main variable(s) of interest 

Let's calculate for each point location the difference between real and estimated number of inhabitants for each matching method (centroid matching, area matching and area-weighted interpolation) and combine the differences calculated for each method.

```{r}

# 1. Difference with Centroid Matching ----
diff_real_centroid <-
  # Perform a left join between the real data and centroid-matched data
  dplyr::left_join(
    # The real inhabitants data joined to points
    points_with_real_inhabitants_municipality,
    # Centroid matched data (drop the geometry for non-spatial comparison)
    centroid_matched |>
      # Drop geometry column, keeping only tabular data
      sf::st_drop_geometry()
  ) |>
  # Create new columns for the differences
  dplyr::mutate(
    # Add a column indicating the type of comparison
    `Type` = "Difference with Centroid Matching",
    # Calculate the difference in inhabitants
    Difference = real_inhabitants_municipality - inhabitants_municipality
  )

# 2. Difference with Areal Matching ----
diff_real_areal <-
  # Left join between real inhabitants data and areal-matched data
  dplyr::left_join(
    # The real inhabitants data
    points_with_real_inhabitants_municipality,
    # Areal matched data (drop geometry for comparison)
    areal_matched |>
      sf::st_drop_geometry()
  ) |>
  # Create new columns
  dplyr::mutate(
    # Indicate the type of comparison
    `Type` = "Difference with Areal Matching",
    # Calculate difference between real and estimated inhabitants
    Difference = real_inhabitants_municipality - inhabitants_municipality
  )

# 3. Difference with Areal Interpolation Matching ----
diff_real_areal_interpolation <-
  # Join real inhabitants data with areal interpolation-matched data
  dplyr::left_join(
    # The real inhabitants data
    points_with_real_inhabitants_municipality,
    # Areal interpolation matched data (without geometry)
    areal_interpolation_matched |>
      sf::st_drop_geometry()
  ) |>
  # Create new columns
  dplyr::mutate(
    # Indicate the comparison type
    `Type` = "Difference with Areal Interpolation Matching",
    # Calculate the difference between real and interpolated inhabitants
    Difference = real_inhabitants_municipality - inhabitants_municipality
  ) |>
  # Ensure unique rows to avoid duplication
  dplyr::distinct()

differences <-
  # Combine rows from all difference data frames into one
  dplyr::bind_rows(
    # Difference data from Centroid Matching
    diff_real_centroid,
    # Difference data from Areal Matching
    diff_real_areal,
    # Difference data from Areal Interpolation Matching
    diff_real_areal_interpolation
  ) |>
  # Drop spatial geometry for non-spatial analysis
  sf::st_drop_geometry() |>
  # Group by matching method type (Centroid, Areal, etc.)
  dplyr::group_by(Type) |>
  # Add indicators for accuracy evaluation
  dplyr::mutate(
    # Binary indicator if Difference is exactly 0 (perfect match)
    correct = ifelse(Difference == 0, 1, 0),
    # Indicator if Difference within ±500 inhabitants
    more_or_less_correct = ifelse(Difference > -500 & Difference < 500, 1, 0)
  ) |>
  # Summarize the data for each matching method
  dplyr::summarize(
    # Median of the Difference column
    median = median(Difference, na.rm = TRUE),
    # Mean of the Difference column
    mean = mean(Difference, na.rm = TRUE),
    # Minimum difference
    min = min(Difference, na.rm = TRUE),
    # Maximum difference
    max = max(Difference, na.rm = TRUE),
    # Standard deviation of the differences
    sd = sd(Difference, na.rm = TRUE),
    # Variance of differences divided by 1000 for scaling
    var1000 = var(Difference, na.rm = TRUE) / 1000,
    # Interquartile range (IQR) of differences
    iqr = IQR(Difference, na.rm = TRUE),
    # Proportion of exact matches (where Difference = 0)
    prop_correct = mean(correct, na.rm = TRUE),
    # Proportion of matches within ±500 inhabitants
    prop_more_or_less_correct = mean(more_or_less_correct, na.rm = TRUE)
  )

# Calculate the differences between inhabitants estimated by Centroid Matching and Areal Matching ----
diff_centroid_areal <-
  # Create a new tibble (data frame) to store the differences
  tibble::tibble(
    # Assign a label for the type of difference calculated
    `Type` = "Difference Centroid and Areal Matching",
    # Calculate the difference in inhabitants between the two matching methods
    Difference = centroid_matched$inhabitants_municipality -
      # Subtract Areal Matching inhabitants from Centroid Matching
      areal_matched$inhabitants_municipality
  )

# Calculate the differences between inhabitants estimated by Centroid Matching and Areal Interpolation Matching ----
diff_centroid_interpolated <-
  # Create a new tibble to store the differences
  tibble::tibble(
    # Label for the difference type
    `Type` = "Difference Centroid and Areal Interpolation Matching",
    # Calculate the difference for this matching comparison
    Difference = centroid_matched$inhabitants_municipality -
      # Subtract Areal Interpolation inhabitants from Centroid Matching
      areal_interpolation_matched$inhabitants_municipality
  )

# Calculate the differences between inhabitants estimated by Areal Matching and Areal Interpolation Matching ----
diff_areal_interpolated <-
  # Create a new tibble to store the differences
  tibble::tibble(
    # Label for the difference type
    `Type` = "Difference Areal and Areal Interpolation Matching",
    # Calculate the difference in inhabitants between the two methods
    Difference = areal_matched$inhabitants_municipality -
      # Subtract Areal Interpolation inhabitants from Areal Matching
      areal_interpolation_matched$inhabitants_municipality
  )

```

Since we are ultimately interested in how the matching compares at the ZIP code level, rather than at the (simulated) point level, we aggregate the population estimate differences at the ZIP code level. 
This process allows us to compare the results of the three different matching methods (centroid matching, areal matching, and areal interpolation matching) and identify which method produces the smallest population difference for each ZIP code.

```{r}

# Aggregate differences at the zip code level ----

diff_real_zip_code_aggregated <-
  diff_real_centroid |>
  # Group data by zip code
  dplyr::group_by(zip_code) |>
  # Drop geometry for non-spatial operations
  sf::st_drop_geometry() |>
  # Summarize by calculating mean difference
  dplyr::summarize(
    # Mean difference for centroid matching method
    mean_difference_centroid = mean(Difference, na.rm = TRUE)
  ) |>
  # Join with the areal matching differences
  dplyr::left_join(
    diff_real_areal |>
      dplyr::group_by(zip_code) |>
      sf::st_drop_geometry() |>
      dplyr::summarize(
        # Mean difference for areal matching method
        mean_difference_areal = mean(Difference, na.rm = TRUE)
      )
  ) |>
  # Join with the areal interpolation matching differences
  dplyr::left_join(
    diff_real_areal_interpolation |>
      dplyr::group_by(zip_code) |>
      sf::st_drop_geometry() |>
      dplyr::summarize(
        # Mean difference for areal interpolation
        mean_difference_areal_interpolation = mean(Difference, na.rm = TRUE)
      )
  )

# Calculate absolute mean differences ----
diff_real_zip_code_aggregated <-
  diff_real_zip_code_aggregated |>
  # Create columns for absolute mean differences
  dplyr::mutate(
    # Absolute value of mean differences (centroid method)
    mean_difference_centroid_abs = abs(mean_difference_centroid),
    # Absolute mean difference for areal method
    mean_difference_areal_abs = abs(mean_difference_areal),
    # Absolute mean difference for areal interpolation
    mean_difference_areal_interpolation_abs =
      abs(mean_difference_areal_interpolation)
  )

# Identify the method with the smallest absolute difference per zip code ----
diff_real_zip_code_aggregated <-
  diff_real_zip_code_aggregated |>
  # Use bind_cols to add the method with minimum difference
  dplyr::bind_cols(
    # Find column name with minimum absolute difference
    min_method = names(diff_real_zip_code_aggregated[-c(1:4)])[
      # Inverse to get min absolute values, excluding grouping cols
      max.col(-diff_real_zip_code_aggregated[-c(1:4)])
    ]
  ) |>
  # Adjust cases with ties for consistency
  dplyr::mutate(
    min_method = ifelse(
      # Tie condition check
      mean_difference_centroid_abs == mean_difference_areal_interpolation_abs &
        mean_difference_centroid_abs == mean_difference_areal_abs,
      # Set to "centroid" if all methods tie
      "mean_difference_centroid_abs",
      min_method
    )
  ) |>
  # Remove intermediate absolute difference columns
  dplyr::select(-contains("abs"))

# Join with zip code geometry and assign codes for each method ----
diff_real_zip_code_aggregated <-
  diff_real_zip_code_aggregated |>
  # Join back with zip code spatial data
  dplyr::left_join(zip_codes) |>
  # Convert back to an sf object for spatial analysis
  sf::st_as_sf() |>
  # Create a code for each method for easier visualization
  dplyr::mutate(
    min_method_code = dplyr::case_when(
      # Assign code 1 for centroid method
      min_method == "mean_difference_centroid_abs" ~ 1,
      # Code 2 for areal method
      min_method == "mean_difference_areal_abs" ~ 2,
      # Code 3 for areal interpolation method
      min_method == "mean_difference_areal_interpolation_abs" ~ 3
    )
  ) |>
  dplyr::mutate(
    difference = dplyr::case_when(
      min_method == "mean_difference_centroid_abs" ~ mean_difference_centroid,
      min_method == "mean_difference_areal_abs" ~ mean_difference_areal,
      min_method == "mean_difference_areal_interpolation_abs" ~
        mean_difference_areal_interpolation,
      TRUE ~ NA
    )
  )
```

## Accuracy of matching methods

- Differences to the 'real' number of inhabitants on average the same between the matching methods

```{r}


# Create a histogram to visualize the distribution of differences for each matching method ----
difference_histogram <-
  # Combine differences from all matching methods into a single data frame
  dplyr::bind_rows(
    # Centroid method differences
    diff_real_centroid,
    # Areal method differences
    diff_real_areal,
    # Areal interpolation method differences
    diff_real_areal_interpolation
  ) |>
  # Remove spatial geometry for visualization purposes
  sf::st_drop_geometry() |>
  # Initialize ggplot with Difference as x-axis variable
  ggplot(aes(x = Difference)) +
  # Add histogram with 10 bins
  geom_histogram(bins = 10) +
  # Limit x-axis for a clear view of the distribution
  xlim(-2500000, 2500000) +
  # Create a separate histogram for each matching method type
  facet_wrap(~`Type`)

difference_histogram

```

## Consistency of matching methods

- Comparison of scaled differences between matching methods
- Narrower, centered distributions suggest better consistency across the matched points.
- Wider, more spread-out distributions suggest more variability in the differences, meaning some methods might be more volatile or less accurate in specific areas.
- 

```{r}

# Create density plots to compare scaled differences across matching methods ----
difference_densities <-
  # Combine pairwise differences for each matching method
  dplyr::bind_rows(
    # Centroid and Areal method differences
    diff_centroid_areal,
    # Centroid and Interpolated method differences
    diff_centroid_interpolated,
    # Areal and Interpolated method differences
    diff_areal_interpolated
  ) |>
  # Group data by matching method type
  dplyr::group_by(`Type`) |>
  # Scale differences for comparability across methods
  dplyr::mutate(Difference = scale(Difference)) |>
  # Initialize ggplot with Difference as x-axis variable
  ggplot(aes(x = Difference)) +
  # Create density plot for distribution visualization
  geom_density() +
  # Set x-axis limits to focus on main data range
  xlim(-10, 10) +
  # Separate density plots by type of matching method
  facet_wrap(~`Type`)

difference_densities

```

This map allows us to identify which method is most consistently successful at minimizing population differences across ZIP codes.

Different matching methods perform better in certain areas. For example, in more populated regions like cities, ZIP codes are usually clearly located within a single municipality, so centroid matching performs very well. 
On average, areal interpolation, which takes more factors into account, performs the best across the entire area. However, this method requires the variable of interest for the matching process which might not always be available.
All in all: Different matching methods perform better in some places.

```{r}


# Create a map to visualize which method minimizes the difference for each zip code ----
diff_real_zip_code_aggregated_map <-
  # Initialize ggplot for map
  ggplot() +
  # Add map layers with fill representing the best matching method
  geom_sf(
    data = diff_real_zip_code_aggregated, aes(fill = min_method), lwd = 0
  ) +
  # Use viridis color scale to differentiate methods
  scale_fill_viridis_d()

# Save the map plot to a file ----
ggplot2::ggsave(
  # Specify file name and output path
  "./test/diff_real_zip_code_aggregated_map.png",
  # Reference the map plot
  diff_real_zip_code_aggregated_map,
  # High resolution for clear saved image
  dpi = 600
)

diff_real_zip_code_aggregated_map_differences <-
  # Initialize ggplot for map
  ggplot() +
  geom_sf(data = zip_codes, lwd = .01) +
  # Add map layers with fill representing the difference
  geom_sf(
    data = diff_real_zip_code_aggregated, aes(fill = difference), lwd = 0
  ) +
  # Use viridis color scale to differentiate differences
  scale_fill_viridis_c() +
  facet_wrap(~min_method)


```

## Effect of matching method on bivariate correlation  

Nearly no difference

```{r, echo = FALSE}

# linked_survey <-
#   survey |> 
#   # Left join with centroid_matched, dropping geometry information
#   dplyr::left_join(centroid_matched |> 
#                      sf::st_drop_geometry(), by = "zip_code") |>
#   # Rename columns for clarity
#   dplyr::rename(cent_inhabitants_mun = inhabitants_municipality,
#                 cent_area_mun = mun_area) |>
#   # Left join with areal_matched, dropping specific columns and geometry
#   dplyr::left_join(areal_matched |>
#                      sf::st_drop_geometry() |>
#                      dplyr::select(-inhabitants_zip_code), by = "zip_code") |>
#   # Rename columns for clarity
#   dplyr::rename(areal_inhabitants_mun = inhabitants_municipality,
#                 areal_area_mun = mun_area) |>
#   # Left join with areal_interpolation_matched, dropping specific columns and geometry
#   dplyr::left_join(areal_interpolation_matched |>
#                      sf::st_drop_geometry() |>
#                      dplyr::select(-inhabitants_zip_code), by = "zip_code") |>
#   # Rename columns for clarity
#   dplyr::rename(interpolation_inhabitants_mun = inhabitants_municipality,
#                 interpolation_area_mun = mun_area)  |>
#   # Calculate population densities based on the joined data
#   dplyr::mutate(
#     cent_pop_dens = cent_inhabitants_mun / cent_area_mun,
#     areal_pop_dens = areal_inhabitants_mun / areal_area_mun,
#     interpolation_pop_dens = interpolation_inhabitants_mun / interpolation_area_mun
#   )
# 
# # Calculate correlations between afd_rating and population density variables
# correlations <-
#   linked_survey |> 
#   # Select relevant columns: afd_rating and those containing "pop_dens"
#   dplyr::select(afd_rating, contains("pop_dens")) |>
#   # Compute pairwise correlations while handling missing values
#   corrr::correlate(use = "pairwise.complete.obs")  |>  
#   # Select only the terms and their correlation with afd_rating
#   dplyr::select(term, afd_rating) |> 
#   # Filter out the correlation of afd_rating with itself
#   dplyr::filter(term != "afd_rating")

```

# Conclusion and recommendations for further analyses

- Short summary
- Recommendation
- Short theoretical discussion about neighbourhood definition (uncertain geographic unit problem)

# References

# Additional material

